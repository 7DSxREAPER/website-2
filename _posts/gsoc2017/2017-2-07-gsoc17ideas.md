---
layout: post
title: Google Summer of Code 2017 Ideas
---

## General information on applications

If you are interested in any of the ideas listed below or you think you can propose something interesting to improve RoboComp we encourage you to apply.
It is important to familiarize with the software first.
You can go through the available tutorials and direct your questions to the mailing list or gitter chat (listed below, also see conctact section).
Please read all the information posted in this page before applying.
Make sure you are familiar with the required skills for the idea.
Since several of the mentioned RoboComp tools and components are not explained here to keep this list short we encourage everyone to check the RoboComp documentation linked below.
Mentors and backup mentors are listed right after the idea explanation.
All mentors contact info is at the end of the page.

**Where can I start and what to include on my application?**   
You are encouraged to go through these steps for a better understading and follow-up of your application.

1. Download and install RoboComp: [https://github.com/robocomp/robocomp/blob/master/README.md](https://github.com/robocomp/robocomp/blob/master/README.md).
2. Follow the tutorials: [https://github.com/robocomp/robocomp/blob/master/doc/README.md](https://github.com/robocomp/robocomp/blob/master/doc/README.md).
3. Once you are familiar with RoboComp and the components and tools involved in the particular idea you want to contribute to, try to understand how these components/tools work and, if possible, their design.
4. Participate in the mailing list asking any question you might have.
5. Create a schedule with the milestones you plan to follow during the GSoC 2017 program.
6. Send the schedule and any code you might have written along with your CV and other application materials to the main mentor of your idea, CC the backup mentor.

General questions about RoboComp:  
[Developers list](https://groups.google.com/forum/?hl=es#!forum/robocomp-dev)  
[Gitter chat](https://gitter.im/robocomp/home)

## IDEAS LIST for GSoC 2017

### 1. Javascript support
NodeJS component code generation.
An interesting diversion from current robotics technologies based on C++ and Python would be the use of Javascript as the language to code some highly concurrent components.
Most components combine push-pull and RPC communication models to talk to other components in their graph of processes.
Additional threads are normally used to handle the components' internal tasks.
In this activity, the current component code generator of RoboComp will be extended to include Javascript running in a server as a new target language for components.
The main restriction here is that ZeroC releases a version of the Ice middleware running on Node, since the web browser version is already out.

Needed skills: Javascript, Python, Cog(python module)  
Mentor: Pablo Bustos  
Backup mentor: Luis J. Manso

### 2. Graphic deployment tool
Currently RoboComp has a component deployment tool that has been improved through several years, rcmanager.
This tool has to be provided with an XML file with the configuration of the network of components to be deployed.
Having this XML file created using a graphical tool would help enormously the configuration of new setups for different projects.
In this idea you will improve the current component management graphical tool to allow roboticists generate these deployment configuration files in an easy way.

Needed skills: Python, C++, Qt  
Mentor: Ramon Cintas  
Backup mentor: Marco A. Gutiérrez

### 3. Connect RoboComp to Gazebo
RoboComp currently has its own simulation tool RCIS (RoboComp InnerModel Simulator).
Despite it is extremely useful for multiple purposes, it does not incorporate physics simulation.
Additionally, several robot models are already available for Gazebo, which is a more spread simulation environment than RCIS.
Having Gazebo as an option for simulating robots using RoboComp will increase the possibilities that our framework can offer to users and developers.
The idea is to connect RoboComp and Gazebo in a similar way ROS is connected to Gazebo.
As a result, simulations in RoboComp could be launched on both simulators (Gazebo or RCIS).

Needed skills: Gazebo, C++, Robotics simulation   
Mentors: Marco A. Gutiérrez  
Backup mentor: Pablo Bustos

### 4. Graphic editor for InnerModel worlds
InnerModel worlds are XML-based files which define the kinematic properties of the robots and their environments.
Writing these files is a tedious and error-prone task if they go beyond a handful of lines. 
Even when InnerModel worlds are done, sometimes modifying its elements or their position becomes cumbersome, and developers end up in a trial-and-error loop until that can take a while.
Having a graphical tool for creating and editing these files would help enormously.

Needed skills: C++, OpenSceneGraph, InnerModel  
Mentor: Luis J. Manso  
Backup mentor: Marco A. Gutiérrez

### 5. Easing deployment, reducing dependencies, “dockering” RoboComp
Docker is a good way to make sure software works independently of the configuration of the system where it is being run.
Having demos of RoboComp enclosed into different docker containers can help with deployment in different machines as well as preserve the integrity of a certain demo when it comes the time to run it.
In addition to writing down the robocomp-docker documentation and related tutorials, you will be in charge of:
* Refactoring the CMake structure within RoboComp: it is needed so basic requirements for installation are reduced to a minimum. On the same page, this activity should ease the task for new developers to add new libraries, classes, tools or modules to the framework.
* Facilitate the deployment on different operating systems, a fully functional Docker container for RoboComp will be developed so instant deployment will be available on heterogeneous platforms through the docker tool.
* A semi-automatic procedure to update changes from the repository to the Docker container will be established.

Needed skills: Docker, GNU/Linux, C++, Python, CMake  
Mentor: Marco A. Gutiérrez  
Backup mentor: Ramon Cintas

### 6. 3D visualization of internal structures in real time 
Many RoboComp components use AGM graph models for cognitive world modeling.
These models are frequently hard to understand, especially when they are big, which they usually are.
Making these graphs easier to read and their information easier to access graphically is a key task that will ease the task of debugging and understanding these cognitive models, and in consequence, the robots' minds.
Specific research and tests with roboticists should be performed in order to find a way of displaying this information that helps anyone understand the whole graph.
Once specific key assets are detected they should be implemented one by one and properly tested with roboticists to ensure they are widely accepted as a proper enhancement.
Several of these features should be developed until the graph becomes easily readable and can be easily managed through the graphical interface provided in RoboComp.

Needed skills: Python, C++, Qt5, OSG  
Mentor: Luis J. Manso  
Backup Mentor: Marco A. Gutiérrez

### 7. Learning useful actions for efficient planning
Many RoboComp components use the AGGLPlanner artificial intelligence task planner.
Despite the many advantages the AGGLPlanner planner has, when tasks are complex and the domain is large, plans take too long to be computed in practice.
An interesting way to improve these times is to reduce the domain size, that is, the number of possible actions that the planner takes into account when searching for the optimum plan.
Of course we don't want to remove useful actions from domain, because it would unable the robots to plan how to achieve their misssions.
Therefore, the goal is to learn which actions are most-likely to be used depending on the mission of the robot and the previous missions and plans.

Lets say the robot has actions related to navigation, actions related to manipulation, and others related to human-robot interaction.
If the robot is aksed to go some place, we would like to try planning such task taking only into account the actions related to navigation.
If the planner cannot find a goal using only those actions, the planning process should be relaunched taking also into account other actions which are more or less likely to be used. 

The task at hand here would be to integrate a machine learning algorithm in AGGLPlanner to learn which actions are most-likely to be used for a target, given information regarding previous planning tasks and their outcomes.

Needed skills: Python, Machine learning__
Mentor: Luis J. Manso__
Backup Mentor: Pablo Bustos


## Mentors info

### Marco A. Gutiérrez
marcogATunexDOTes  
PhD Student, RoboLab,  
University of Extremadura  

### Pablo Bustos
pbustosATunexDOTes  
Full Professor, RoboLab,  
University of Extremadura  

### Luis J. Manso
lmansoATunexDOTes  
Postdoc Researcher, RoboLab,  
University of Extremadura  

### Ramon Cintas
rcintasATunexDOTes  
Researcher, Robolab,  
University of Extremadura  

### Felipe Cid
felipe.cidATuachDOTcl  
Professor, Electricty and Electronic Institute  
Austral Unviersity of Chile  

